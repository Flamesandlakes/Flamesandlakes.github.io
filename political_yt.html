<!DOCTYPE html>
<html lang="en">
<head>
<title>American Politics on Youtube</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="custom_layout.css"> <!-- href="https://www.w3schools.com/w3css/4/w3.css"> -->

<script>
  // Function to initialize the image cycler
  function initializeImageCycler(elementId, images, initialDelay = 2000, cycleDelay = 2000, transitionDelay = 4000) {
      let currentIndex = 0;

      // Function to cycle through images
      function cycleImage() {
          currentIndex = (currentIndex + 1) % images.length;
          if (currentIndex === 0 || currentIndex === images.length - 1) {
              setTimeout(() => updateImage(currentIndex), transitionDelay);
          } else {
              updateImage(currentIndex);
          }
      }

      // Function to update the image source
      function updateImage(index) {
          document.getElementById(elementId).src = images[index];
          setTimeout(cycleImage, cycleDelay);
      }

      // Start the cycling process
      setTimeout(cycleImage, initialDelay);
  }

  // Define the image set

  const HDBSCANnoise_images = [
      'images/political_yt/loop/UMAP_hdbscan_1v.png',
      'images/political_yt/loop/UMAP_hdbscan_2v.png',
  ];

  const HDBSCANbounds_images = [
      'images/political_yt/loop/UMAP_hdbscan_2v.png',
      'images/political_yt/loop/UMAP_hdbscan_3v.png',
      'images/political_yt/loop/UMAP_hdbscan_5v.png',
      'images/political_yt/loop/UMAP_hdbscan_4v.png'
  ];

  // Initialize the image cycler with the desired parameters
  initializeImageCycler('displayHDBSCANnoise', HDBSCANnoise_images, 1000, 1000, 2000) ;
  initializeImageCycler('displayHDBSCANbounds', HDBSCANbounds_images);
</script>

  
 <!-- 
  <style>
   
    .image-container {
      text-align: center;
      overflow: visible;
      position: relative;
      width: 100%;
      height: auto; /* Limit height to viewport height */
    }
  
    .responsive-img {
      width: 180%;
      height: auto;
      display: block;
      margin: -30%;
    }
      </style>
  -->
<style> 
  .image-container {
    text-align: center; 
    overflow: visible; /* Prevent content from overflowing */
    position: relative;
    width: 100%;
    margin: 20px 0; /* Add spacing between containers */
  }

  .responsive-img {
    width: 120%; /* Make the image larger than the container */
    height: auto;
    display: block;
    margin-left: -10%; /* Center the image by offsetting it */
    position: relative;
    z-index: 1; /* Ensure images are layered correctly */
  }

  h3 {
    margin-top: 40px; /* Add spacing above headings */
  }

  div.scroll-container {
    background-color: white;
    overflow: auto;
    white-space: nowrap;
    padding: 10px;
  }
  
  div.scroll-container img {
    padding: 50px;
  }

  td {
    padding-left: 20px;
    padding-right: 20px;
    padding-top: 5px;
    padding-bottom: 5px;

  }

  td > tr:nth-child(0) {
    font-weight: bold;
 }

 tr + td {
  font-weight: bold;
}

/* Tooltip container */
.tooltip {
  position: relative;
  display: inline-block;
  border-bottom: 1px dotted black;
  font-style: normal;
}

.tooltip .tooltiptext {
  visibility: hidden;
  width: 320px;
  background-color: black;
  color: #fff;
  text-align: center;
  border-radius: 6px;
  padding: 5px 0;
  font-weight: normal;
  
  /* Position the tooltip */
  position: absolute;
  z-index: 1;
  top: -5px;
  left: 105%;
}

.tooltip:hover .tooltiptext {
  visibility: visible;
}



  </style>

</head>
<body>

<!-- Header -->
<header class="w3-display-container w3-content w3-center" style="max-width:1500px">
  <img class="w3-image" src="https://images.pexels.com/photos/8850709/pexels-photo-8850709.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1600" alt="Election" width="60%" max-width=1280 style="opacity:0.7">
  <!-- <img class="w3-image" src="https://images.pexels.com/photos/51929/medications-cure-tablets-pharmacy-51929.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1" alt="Medicine" width="60%" max-width=1280 style="opacity:0.7">
-->
  <div class="w3-display-middle w3-padding-large w3-border w3-wide w3-text-light-grey w3-center">
    <h1 class="w3-hide-medium w3-hide-small w3-xxxlarge" style="color: blue; opacity: 0.8; text-shadow: 4px -1px white, 6px -3px red"><b>ONLINE DISCOURSE & AMERICAN POLITICS</b></h1>
    <h5 class="w3-hide-large" style="white-space:nowrap" style="color: black; opacity: 1;"><b>ONLINE DISCOURSE & AMERICAN POLITICS</b></h5>
    <h3 class="w3-hide-medium w3-hide-small" style="color: white; opacity: 0.9; text-shadow: -1px -1px black, 1px 1px black, -1px 1px black, 1px -1px black, 
    -2px -2px black, 2px 2px black, -2px 2px black, 2px -2px black">
      <b>Political content on Youtube<br>before and after<br>the 2024 American Presidential Election</b></h3>
  </div>
  
  <!-- Navbar (placed at the bottom of the header image) -->
  <div class="w3-bar w3-light-grey w3-round w3-display-bottommiddle w3-hide-small" style="bottom:-16px">
    <a href="/" class="w3-bar-item w3-button">Return to Home Page</a>
    <!--
    <a href="#data" class="w3-bar-item w3-button">Data</a>
    <a href="#exploration" class="w3-bar-item w3-button">Exploration</a> -->
  </div>
</header>

<!-- Navbar on small screens -->
<div class="w3-center w3-light-grey w3-padding-16 w3-hide-large w3-hide-medium">
<div class="w3-bar w3-light-grey">
  <a href="/" class="w3-bar-item w3-button">Return to Home Page</a>
  <!-- 
  <a href="#data" class="w3-bar-item w3-button">Data</a>
  <a href="#exploration" class="w3-bar-item w3-button">Exploration</a>
  -->
</div>
</div>


<!-- Side navigation -->
<div class="navbar">
  <a href="#">Introduction</a>
  <a href="#wordFrequencies">What do they say?</a>
  <a href="#topicalAnalysis">What topics are talked about?</a>
  <a href="#sentimentOverTime">What are their sentiments?</a>
  <a href="#dialogueUMAP">How similar are the videos to each other?</a>
  <!--
  <a href="#timeOnMarket">How long does products stay on market?</a>
  <a href="#varianceInPrice">Why does medicine prices vary?</a>
  -->
  <a href="/">Return to Home Page</a>
</div>


<!-- Page content -->

<div class="w3-content w3-padding-large w3-margin-top">

  <!-- Title -->

  <div class="w3-panel w3-pale-yellow w3-display-container w3-border">
    <h4>Be aware!</h4>
    <p>Later sections of this page contain flickering images. 
    However, the flickering rate should not exceed 1 Hz.</p>
    <span onclick="this.parentElement.style.display='none'"
    class="w3-button w3-large w3-display-bottomright">&times;</span>
  </div>

  <h1  id="data">Introduction</h1>
    
    <p>
      2024 was an election year in the United States of America - the world's second largest democracy. Political discourse is arguably central to democratic societies. And in the age of digital media, it is hard to understate the role that online content plays in political discourse. 
      <br><br>
      There are many facets of online political discourse. 
      I will be focusing on political commentators on Youtube. Though depending on the definition, they may also be considered to be online influencers. 
    </p>

    <h3>
      What I am curious about
    </h3> 
    <p>
    At the heart of it all, I am curious about whether and how commentators mirror each other. 
    In terms of sentiments, do they follow the same, inversed or different paths as time progresses.
    In addition, I wonder there was a shift after the election, 
    and if so, immediately after or at a different time such as after the inaugeration.  
    </p>


    <h3>About the data</h3>
    <p>
      The data used in this project is collected from Youtube channels representating various left- and right-leaning political commentators.</a>.
      On a sidenote in terms of terminology, I will refrain from labelling commentators as being Democrats or Republicans as this does not necessarily align with how they politically identify themselves.
      The dataset covers <b>12795</b> individual videos with their corresponding transcripts. The total runtime of these videos are <b>4868.3</b> hours, which translates to more than 202 days worth of watch time.
      The data is sourced from a selection of 10 Youtube channels with 9 corresponding political commentators as a pair of channels belong to the same commentator. 
      As such, this project is closer to representating a snapshot than the full picture of the online political discourse, despite the aforementioned quantity of data.  
      I will primarily focus on the contents of these video transcripts. I am aware that some of these transcripts may be based on auto-generated subtitles, which may be prone to occassional misannotations. 
      I am assuming that these are minor in the grand scheme of things. But I will also later validate sampled transcripts to evaluate the validity of these transcripts.  
      
    </p>
    <p>
      The data includes videos published on their respective channels, in the time window spanning from the 1st of June 2024 to the 18th of March 2025.
      <br>
      Additional variables on each video include the video title (at the time of data collection), the channel that posted it, the length of the video, when it was published alongside a couple of other variables.
      <br> 
    </p>
      
    </p>
   
   <p>
    
  </p>
</div>
<div class="w3-content w3-padding-large w3-margin-top" >
  <h2 id="wordFrequencies">What do they say?</h2>

  <p>
    That is central to what I want to know. Though I am equally interested in partisan divides, i.e. whether the content of videos differ based on the political leaning of the creator.
    A qualitative approach may be considered if not for the scale of the data. This is to the benefit of quantitative textual analysis, which may reveal insights that otherwise would be infeasible to uncover. 
    <br><br>
    The most straightforward strategy to begin with is counting words. Not manually, of course.
    <br>
    It is noted that super common words, that are otherwise present to pad out or structure sentences, <em class = "tooltip">are left out<span class ="tooltiptext">Or are at least supposed to be left out in theory.</span> </em>. 
    These words are called stopwords and they include words such as "is", "are", "not", "he", "she", "it", "you", "me" etc.
    <br> Additionally, all words are processed as lowercase including names and acronyms.
    <br><br>
  </p>
    Now, the ten most frequent words across the 12795 videos are:<br>
    
    <ol>
      <li><b>like</b> - 209229 times.</li>
      <li><b>uh</b> - 162406 times.</li>
      <li><b>know</b> - 161583 times.</li>
      <li><b>people</b> - 130855 times.</li>
      <li><b>going</b> - 127803 times.</li>
      <li><b>trump</b> - 116439 times.</li>
      <li><b>thats</b> -  116390 times.</li>
      <li><b>dont</b> -  108821 times.</li>
      <li><b>right</b> - 97551 times.</li>
      <li><b>think</b> - 95087 times.</li>
    </ol>
    
    <p>
    Well, uh, it seems like I have not accounted for interjections such as "uh", which arguably is not meaningful on its own. 
    Though to play devil's advocate, that applies to most words without a surrounding sentence.
    [These cases might be left out in later topical analysis, where interjections does not relate nor convey the topic at hand.]
    </p>
    <p>
    As it pertains to potential partisan differences, 
    the respective top ten words for left-leaning and right-leaning commentators are very similar. 
    The definition of common words is still somewhat loose, as there is definitely an argument to be made, 
    that some of these words are still filler words. 
    I would consider "uh","thats", "dont" and "going" as examples of such. 
    The case is less clear regarding the other words. The one word I would certainly not consider to be filler is "trump" (or "Trump").
    </p>
    <p>
      The two top ten lists does not aid in discerning how the two political grouping differ from each other.
    </p>

    <!-- [[NOTE: What is the word count per video per leaning?]] -->
    <br><br>
    
  <div style="display: inline-block">
    Words counts among left-leaning channels 
    <ol>
      <li><b>like</b> - 100257 times.</li>
      <li><b>know</b> - 72249 times.</li>
      <li><b>uh</b> - 64264 times.</li>
      <li><b>trump</b> - 62017 times.</li>
      <li><b>going</b> - 55016 times.</li>
      <li><b>people</b> - 54646 times.</li>
      <li><b>thats</b> - 51287 times.</li>
      <li><b>dont</b> -  46238 times.</li>
      <li><b>right</b> - 45282 times.</li>
      <li><b>think</b> - 38102 times.</li>
    </ol>
  </div>
  <div style="display: inline-block"> 
    &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;
    &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;
  </div>
  <div style="display: inline-block">
    Words counts among right-leaning channels 
  <ol>
    <li><b>like</b> - 108972 times.</li>
    <li><b>uh</b> - 98142 times.</li>
    <li><b>know</b> - 89334 times.</li>
    <li><b>people</b> - 76209 times.</li>
    <li><b>going</b> - 72787 times.</li>
    <li><b>thats</b> - 65103 times.</li>
    <li><b>dont</b> -  62583 times.</li>
    <li><b>think</b> -  56985 times.</li>
    <li><b>trump</b> - 54422 times.</li>
    <li><b>right</b> - 52269 times.</li>
  </ol>
</div> 
<p>
  Now, the insight provided by this comparison between two lists of 10 words each is limted, to be frank.
  Besides being able to tell that Trump is key figure to both political leanings, 
  it does not tell us much about the bigger picture.
</p>
<p>
  What if we quantify the differences between these lists instead? 
  For any given number - with that number being how many words from the top we list - I can count how many words appear in one list but not in the other. 
  Let us look at the first three comparisons as an example. 
  The first comparison is between the top 1 word of each leaning. 
  That is "like" in the case of both lists. The difference is zero.
  <br>
  The second comparison is between the top 2 words of each leaning.
  That is "like" and "know" in comparison to "like" and "uh". 
  "uh" is not in the first list, while "know" does not appear in the second list. 
  It does not matter from which list we reference, as in either case the difference is one word. 
  <br>
  For the third pair of lists, "like", "know" and "uh" is compared to "like", "uh" and "know". 
  As we ignore the order in which the words appear, the words of the two lists are identical to each other.
  The difference is once again zero.
</p>
<p>
  Each step introduces two words, resulting in one of four outcomes. <br>
  <ol>
  <li>The words are different to each other and does not appear on the other existing list of words. The difference is increased by one.</li>
  <li>Each word are identical to each other. The existing difference neither increases nor decreases.</li>
  <li>Each word are different, but they have each previously been listed on the other list. The difference is decreased by one.</li>
  <li>Each word are different, but one is already listed on the other list, while the inverse does not apply to the second word. The existing difference neither increases nor decreases. 
    This outcome may be thought of a combination of the first and third outcome, but spread out between a prior pair and the current pair of words.</li>
</ul>
  <br><br>
  We can visualise this progression in number of differences through a bar plot.   
</p>
<img src="images/political_yt/set difference_among top words_left vs right_default stopwords removed_first 10.png">
<p>
  Once the entire respective top 10 lists are compared to each other, there are no differences in terms of the words contained one list but not in the other. 
  <br><br>
  Now, what happens when we observe the first 100 lists. 
  Though remember that the further down the list we go, the less frequent these words will be compared to the prior steps. 
  There will theoretically be a point at which a difference in observed frequency is marginal. 
  This is something I will delve into later, but for now, the top lists of the smaller sizes are more generally worthy of note (though unless stopwords are present) until we reach a (yet to be determined) point.
  The top third most common word will simply generally play a much more central role in the content than the 117th most common word.    
</p>
<img src="images/political_yt/set difference_among top words_left vs right_default stopwords removed_first 100.png">
<p>
  While the third outcome also occurs after this point, the other outcomes are more common, specically the first outcome.
  The top 10 lists are revealed to be quite rare, if not unique, in this bigger range of list sizes.  
  All comparisons between top lists beyond the 10th have atleast one difference, with a tendency to increase more than decline. 
  That said, there are a least of couple sequential sizes, where the number of differences is unchanged.
  <br>
  After 100 comparisons, there are 8 words that are unique to their respective list. 
  That means that they share the other 92 words.  
  As for the words that make up the difference, they are:
</p> <br>


<div style="display: inline-block;">

  Words unique to left-leaning channels' top 100
<table border="1" class="dataframe">
  <thead>
    
    <tr style="text-align: center; padding: 10px;">
      <th style = "font-weight: bold;">Word</th>
      <th>Rank<br> among <br>&nbsp;&nbsp; the Left &nbsp;&nbsp;&nbsp;</th>
      <th>Rank<br>among <br>&nbsp;&nbsp;&nbsp; the Right &nbsp;&nbsp;</th>
    </tr>
  </thead>
  <tbody style="text-align: center;">
    <tr>
      <td>speaker</td>
      <td>55</td>
      <td>1786</td>
    </tr>
    <tr>
      <td>trumps</td>
      <td>66</td>
      <td>194</td>
    </tr>
    <tr>
      <td>hey</td>
      <td>81</td>
      <td>307</td>
    </tr>
    <tr>
      <td>money</td>
      <td>82</td>
      <td>108</td>
    </tr>
    <tr>
      <td>stuff</td>
      <td>86</td>
      <td>114</td>
    </tr>
    <tr>
      <td>election</td>
      <td>87</td>
      <td>119</td>
    </tr>
    <tr>
      <td>vote</td>
      <td>94</td>
      <td>128</td>
    </tr>
    <tr>
      <td>war</td>
      <td>95</td>
      <td>126</td>
    </tr>
  </tbody>
</table>
</div>

<div style="display: inline-block"> 
  &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;
  &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;
</div>


<div style = "display:inline-block;">
  Words unique to right-leaning channels' top 100
  <table border="1" class="dataframe">
    <thead>
      <tr style="text-align: center;">
        <th style = "padding: 10px;">Word</th>
      <th>Rank<br> among <br>&nbsp;&nbsp; the Left &nbsp;&nbsp;&nbsp;</th>
      <th>Rank<br>among <br>&nbsp;&nbsp;&nbsp; the Right &nbsp;&nbsp;</th>
    </tr>
  </thead>
  <tbody style="text-align: center;">
    <tr>
      <td>world</td>
      <td>109</td>
      <td>80</td>
    </tr>
    <tr>
      <td>american</td>
      <td>103</td>
      <td>81</td>
    </tr>
    <tr>
      <td>put</td>
      <td>102</td>
      <td>84</td>
    </tr>
    <tr>
      <td>last</td>
      <td>112</td>
      <td>85</td>
    </tr>
    <tr>
      <td>fact</td>
      <td>116</td>
      <td>93</td>
    </tr>
    <tr>
      <td>work</td>
      <td>115</td>
      <td>95</td>
    </tr>
    <tr>
      <td>media</td>
      <td>101</td>
      <td>98</td>
    </tr>
    <tr>
      <td>white</td>
      <td>172</td>
      <td>100</td>
    </tr>
  </tbody>
  </table>

</div>
<p>
  The difference in how the words rank by popularity between each side indicates "delays" or "displacement", for lack of a better word.
  Some words simply are more popular for one side than the other, 
  but that does not mean that they are omitted or even rare by the other side of the political aisle.
  See "media". It is the 98th most popular word among the right and just outside the top 100 among the left.
  The notable exceptions are cases such as "speaker" and "white". I will be looking into quanitfying disparities in ranking later.
</p>

<p>
  So far, the increase in difference suggests that the vocabulary of each side is distinct, though not completely unique from each other. 
  Though approaching linguistic differences based on top lists is inherently limited and even potenially misleading. 
  The rate of increase (or decrease) can never surpass 1 per step. 
  Likewise, the plot might give the illusion of a steady climb, though the possible difference is capped by the size of the top lists that are being compared.
</p>

<img src="images/political_yt/set difference_among top words_left vs right_default stopwords removed_first 20000.png">
<p>
There does not appear to be a point of convergence as the two lists mostly continue differentiate in what words are most popular among them.  
Here are some sample words that exhibit the relatively biggest differences in ranking by popularity.
<br><br>
The following words are relatively more prominent among left-leaning content in contrast to right-leaning: "arming", "warmongering", "imperalism", "Kushner" and "Conway".
The first three words point towards the issue of (aggressive) foreign policy, while the last two of these sampled words point towards Conservative public figures.
<br><br>
And the inverse, that is words more prominent among right-leaning content, include: "studios". "theaters", "uncensored", "Ferguson" and "Nashville".
There is admittedly less of a clear theme here. 
Studios and theaters are locations for physical entertainment, potentially capturing segments of self-promotion in the video content. 
"Uncensored" might play into this, though depending on the context, it might be more related to the issue of free speech. 
There are two city names, Ferguson and Nashville, which share a history of political riots. 
This latter aspect does not necessarily play into their mention, but I consider it relevant to their signficance in a political context. 
</p>
</div>

<!--
    <div class="w3-content w3-padding-large w3-margin-top">
  <h2 id="topicalAnalysis">What topics do they cover?</h2>

</div>
-->

<div class="w3-content w3-padding-large w3-margin-top">
<h2 id="sentimentOverTime">What are their sentiments?</h2>
Sentiments describes what kind of emotion is expressed based on the language used. 
In this case, I am applying the NLTK Sentiment Intensity Analyzer to the sentence of each video transcript and find their compounded sentiment. 
As noted, this is based on intensity ranging from negative, to neutral, and to positve. 
This may be considered a bit black-and-white (and a bit of grey), as I am unable to discern for example whether a negative sentiment is due to anger, fear or a different negative emotion.
<br><br>
Note that there is a scrollbar for each of the timelines depicted below. To see the timeline in full, you may zoom out via your browser settings or right-click to view in a seperate window.  

</div>
</div>


  <div class="w3-content w3-padding-large w3-margin-top">
    <h3>Average sentiment over time</h3>
    <img src="images/political_yt/sentiment over time_overall_by YWeek_2024W22_2025W08.png" ;max-width="100%">
  <br><br>
  See below zoomed-in and scrollable verion of this plot.
  </div>

  <div class="scroll-container">
    <img src="images/political_yt/sentiment over time_overall_by YWeek_2024W22_2025W08_fsize44 6.png" ;max-width="100%";class="center">
  </div>

  <div class="w3-content w3-padding-large w3-margin-top"> 
    At no point does the average sentiment cross into the negative values. There are a couple of peaks and downward turns, and them seem to be less stable after early August (Week 32) of 2024.
    <br><br>
    I am also interested in how this changes over time within partisan lines.
  </div>

 
  <div class="w3-content w3-padding-large w3-margin-top">
    <h3>Average sentiment over time by political leaning</h3>
    <img src="images/political_yt/sentiment over time_grouped by leaning_by YWeek_2024W22_2025W08.png" ;max-width="100%">
  <br><br>
  See below for zoomed-in and scrollable verion of this plot.
  </div>

  <div class="scroll-container">
  <img src="images/political_yt/sentiment over time_grouped by leaning_by YWeek_2024W22_2025W08_fsize44 6.png";max-width="100%";class="center">
</div> 

<!-- 

    <center><h3>Average sentiment over time by each channel</h3></center>
  <div class="scroll-container">
    <img src="images/political_yt/sentiment over time_grouped by channel_by YWeek_2024W22_2025W08_fsize44 6.png" ;max-width="100%";class="center">
  </div>
-->

<div class="w3-content w3-padding-large w3-margin-top">
  <h2 id="dialogueUMAP">How similar are the videos to each other?</h2>
  <p>
  In order to determine how similar videos are to each other, I need a way to compare videos, specifically their transcripts. 
  In this case, I am using TF-IDF, which basically meaure the importance of each word in a video relative to its overall occurence across all video transcripts.  
  If a word is observed multiple times within a particular transcript, while the word otherwise is not common among the other transcripts, then the word is measured to have a higher importance to the particular transcript. 
  These measures are then vectorized and then reduced to two dimensions to allow for 2D visualisation. 
  This last step involves UMAP, which is a dimensionality reduction technique that conserves the neighborhoods of each data point 
  - that is the videos that are similar to each other in regards to the words that important to them.
  </p>
  <p>
  I emphasize that the values associated with a video's coordinates within the UMAP representation carry no meaning outside of context. 
  What matters is what other videos are closer to it, i.e. the videos that it form a cluster or "neighbourhood" with. 
  </p>
  <p>
    Clustering techniques may be employed to extract these clusters.
    But first, I want to interpret and infer the characteristics of clusters visually through additional variables. 
    This include the time for when the videos were published, their sentiment, the leaning of their respective channels among other factors.
  </p>
</div>
<!-- 
So,
1. UMAP graded by time
2. UMAP graded by sentiment
3. UMAP colored by leaning
4. UMAP colored by channel
...
5. UMAP by clusters

Overvej at rename title, så reflekterer det specifikke plot
-->
<center>
  <img src="images/political_yt/UMAP_timeline gradient_w colorbar_Political Commentary.png";max-width="100%";class="center">
</center>

<!-- --> 
<div class="w3-content w3-padding-large w3-margin-top">
<p>
  Let us first look at the structure of the data points, each representating a video transcript. In this regard, there is a global structure as well as multiple local structures. 
  Foremost, there is a central cluster with minimal spaced seperation, potentially consisting of multiple subclusters depending on how granular our definition is. 
  This center is surrounded my chained, or "snake-like", clusters. 
  Does this mean that these videos in the clustered in the center likewise are central to the political discourse? 
  No, it simply indicates their close proximity to each other relative to all other videos.  
  The contrast to note lies in that multiple videos are closer to each other, where as the videos in the chains have neighbouring videos that are similar but are further from their neighbours. 
  This may point to some sequentiel order in which the content of the videos gradually shifts. 
</p>

  <p>
The color gradient represents the time of publishing counted in the number of days since June 1st (the start of the time window from which the data has been collected from). 
For reference, the number of days from June 1st to November 5th (Election Day) is 157 days. 
</p>
<p>
It is possible to visually interpret a temporal divide, which 
 - based on the gradient change - is before and after the Election. 
 This also supports the notion that the chained clusters represents a gradual shift, specifically occuring over time. 
 That said, the divide is not a clear break nor do clusters necessarily only consist of videos that are temporally adjacent. 
 
</p>
</div>
<!-- -->

<center>
<img src="images/political_yt/UMAP_sentiment gradient_w colorbar_Political Commentary.png";max-width="100%";class="center">
</center>

<div class="w3-content w3-padding-large w3-margin-top">
<p>
In extension of the timelines plotted earlier, we already know that the average video holds a positive sentiment. 

<br>
Behind the scenes I am working on finding and adjusting a color scheme, where the color of the negative cases more clear stand out among the majority of positive cases.
</p>
</div>
<center>
  <img src="images/political_yt/UMAP_partisan leaning_w legend lower right_Political Commentary.png"; max-width="100%";class="center">
</center>

<div class="w3-content w3-padding-large w3-margin-top">
<p>
The chain-shaped clusters belong for the most part to a specific leaning. 
This could suggest a partisan difference in what topics they cover, or in the very least the words and language, between each side. 
However there are some intersections, not to mention the center, where videos from each leaning are mixed among each other. 
Even so, it is noteworthy how most of the clusters are relatively seperated on the basis of political leaning. 

</p>

<h3 id = "cluster_ideals">Cluster analysis</h3>
<p>
  I have so far visually analysed the plotted data. 
  This have involved on approximate descriptions of clusters, 
  which are difficult to distinctively seperate based on said descriptions alone.
  That said, there are clustering algorithms that each provide a way to assign cluster membership.
  These rely predominantly on unsupervised learning and are fine-tuned according to intrinsic evaluation metrics.
  As such, we should question what sort of truth of the data a given clustering algorithm reveals.
  Ideally, data points that are similar should belong to the same cluster, 
  and the inverse applies for data points disimilar to each other.
  Thus the distance between members of the same cluster should be short,
  while the distance to non-members should be bigger if not great.
</p>

<p>
  I will highlight two clustering algorithms, 
  one that is centroid-based, K-means, and another that is density-based,<em class="tooltip"> in the form of HDBSCAN.
    <span class = tooltiptext>Note: HDBSCAN also contains hiearchical elements.</span>
  </em>
  To be transparent, 
  I have a clear preference among these two algorithms based on the compatability with the nature of the data itself.
  I am showcasing both as there is still some utility to be illustrated by the first case. 
</p>

<p>The K-means algorithm is relatively straightforward. 
  <br>First, randomly assign the position of a <em class="tooltip">K-number<span class = "tooltiptext">K is pre-selected. Intrinsic evaluation metrics may inform which value for K is best.</span></em> of cluster centers. 
  <br>Second, for each data point, assign them to the closest center. 
  <br>Third, update the positions of the centers such that they correspond to the mean position of the newly assigned clusters.
  <br>Repeat steps two and three until there are no changes in assigned membership.
  <br> 
</p>
<p>
  In this case, I arrive at a clustering with five centers. 
  That results in the following clustering.
</p>

</div>

<center>
  <img src="images/political_yt/UMAP_kmeans_k5_centroids in voronoi diagram_Political Commentary.png"; max-width="100%";class="center">
</center>

<div class="w3-content w3-padding-large w3-margin-top">
<p>
The colored diamond shapes indicate the position of their respective cluster center. 
The diamonds themselves does not necessarily correspond to any actual data points. 
But they do partition the space into five distinct regions. 
Here lines are drawn according to which cluster center is closest. 
As a sidenote, these boundary lines technically run to 
<em class="tooltip">infinity.<span class = "tooltiptext">Of course, this have no practical implications for a UMAP projection.</span></em>
</p>

<p>
By now, you might have noticed some discrepancies, namely with <a href = "#cluster_ideals">the previously mentioned cluster ideals</a>.  
There are multiple instances where members of a cluster are in closer proximity to members of a different cluster relative to their own assigned cluster.
The K-means does not quite capture the chain-like structures that I noted earlier. 
With its centroid-based cluster assignment, the K-means clustering algorithm excells at partioning the space into more manageable regions. 
But it fails to capture neighbourhoods that do not conform to a circular origin. 
</p>

<p>
  I want clusters that does not span across empty space and emphasises the proximity between data points themselves.
  In this case, I have already hinted at a clustering algorithm that solves this problem, that being 
  <em class="tooltip">HDBSCAN.<span class = "tooltiptext">Short for Hiearchical Density-Based Spatial Clustering of Applications with Noise</span></em>
  It is admittedly more advanced than the K-means algorithm.
  There is no longer a K to worry about. 
  Instead, we are interested in density - that is the distance to a data point's nearest neighbours.
  Imagine that each data point start off as their own cluster.
  That is the densest possible cluster. 
  Then we expand out from each data point and merge with other data points, thus gradually decreasing the density the further the distance is expanded.
  This allows for tracking which data points merge into clusters together across the range of possible densities.
  The merging of data points forms a hiearchical tree, going from the smallest and most dense to the biggest and least dense merged clusters. 
  A threshold for <em class = "tooltip">the minimum viable cluster size is set
    <span class = "tooltiptext">This minimum size is pre-selected, similar to K in K-means. Intrinsic metrics are likewise used to inform the optimal selection.</span></em>, 
    which allows for pruning out clusters falling under this threshold.
  With that set, clusters are considered stable by the variance of densities by which the clusters do not change. 
  A cross-section of the total most stable clusters are then used for assignment.
  This cross-section is not limited to any particular single level of density, however lower branches of the hiearchy are barred from selection if their "parent" branch is selected.  
</p> 
  
<p>
  It is possible for data points to not be part of a valid cluster as a product of the minimum cluster size. 
  That is not a problem, but it is rather a feature. 
  Such cases are considered noise - from a clustering standpoint. 
  In this case, the instrinsic evaluation metric finds the optimal clustering with a minimum cluster size configured to be 40.
  This results in the following clustering, where the approximate quarter of the total videos 
  - considered to be noise by the HDBSCAN algorithm - are left out. 
</p>
</div>

<center>
  <div >
    <img id="displayHDBSCANnoise" src="images/political_yt/loop/UMAP_hdbscan_1v.png"; max-width="100%";class="center">
</div>

</center>

<div class="w3-content w3-padding-large w3-margin-top">
<p>
Data points classified as noise are not inherently invalid. 
They are considered noise in the sense that do not form a sufficiently large cluster together with any other data points.
When comparing the plots with and without noise, there are of course differences. 
64.75% of the data are not classified as noise.  
They form 31 unqiue clusters according to the HDBSCAN clustering algorithm. 
This is substantially more granular than the five clusters produced by the Kmeans algorithm.
</p>
<p>
  Now, since HDBSCAN does not involve centroids nor is it parametric, 
  the cluster boundaries only play a part in visualisation, 
  to aid in visually seperating clusters from each other since the color palette does not contain 31 easily distinguishable colors.
  Even in cases, where two distinct but close clusters share the same color, spacing between them indicate their seperation.
  That said, these boundaries are artifically constructed by approximation. 
  So they can be fairly rough.
  They rely on the spatial prediction of a supervised K-Nearest Neighbors model fed on the cluster labels. 
  It is thus mostly based on the cluster label of the nearest points across space, which includes noise to provide the seperation.
  Further analysis will still rely on the original cluster labels and not these boundaries as the latter is solely meant for visualisation.
</p>
</div>

<center>
  <div >
    <img id="displayHDBSCANbounds" src="images/political_yt/loop/UMAP_hdbscan_2v.png" ; max-width="100%";class="center">
</div>
</center>
<div class="w3-content w3-padding-large w3-margin-top">
<p>
<!-- NOTE: add labels to last two images in 2nd cycle-->
Each cluster represents a group of similar content.
Now the questions is: What characteristics distinguishes each cluster?
In extension of the prior visual analysis, I remain interested in how the clusters are distributed by partisanship as well as time.
In this regard, I will be moving away from the UMAP projection and instead rely on cluster labels. 
To help with this transition, I will leave you with this plot, where the clusters are labelled accordingly through C1 to C31.
This should provide a frame of reference. 

</p>
</div>

<center>
  <div >
    <img src= "images/political_yt/UMAP_hdbscan_mcs 40_cmap Dark2_v2_w_labels_Political Commentary.png"; max-width="100%";class="center">
    
</div>
</center>

<div class="w3-content w3-padding-large w3-margin-top">
  <p>

  </p>
</div>


<div class="w3-content w3-padding-large w3-margin-top">
  <h2>Validation</h2>
  <p>
   The video transcripts, which the analysis is based on, is not without flaws.
   By looking at a sample of transcripts and comparing them to the original videos, I find certain limitations.
   One limitations is the misspelling of words of foreign origin, especially if their phonetic pronouanciation is different to their spelling. 
   An example of this is names of people from non-English speaking countries, in particular when these names contain multiple unique syllables.  
   Another limitation pertains to acronyms as they are not necessarily identified as such.
   A notable example of this is 
   <em class="tooltip">"MAGA"<span class = "tooltiptext">Short for the slogan <br>"Make America Great Again"<br> and its associated political movement</span></em>  being transcribed as "magga" on occassion. 
   That said, the auto-generated transcription is a double-edged sword. 
   The transcriptions allows for gaining access to a multitude of data that otherwise would be infeasible to collect and analyze. 
   But that volume of data also hinders a thorough quality control of said data. 
   I consider these limitations to be acceptable, but more sensitive cases might require a different or more nuanced approach, likely involving mixed methods.    
  </p>
</div>
  <div class="w3-content w3-padding-large w3-margin-top">
    <h2>Summary</h2>
    <p>
   So, what has the data shown me?
   <br><br>
   The vocabularies used by either side are similar to each other at their core. 
   Among their respective lists of top 100 words (by occurence), 92 words appear across both lists. 
   That said, there are still linguistic differences that reflect partisan issues and attitudes.    
   <br><br>
   The collected data provides a timeline.
   While sentiment have been stable through most of the timeline, we see a dive towards a less positive attitude in left-leaning content in the most recent data. 
   Though I can not say whether this dive represents a short-term spike or a long-term trend. 
   <br><br>
   As I look at clusters of videos, grouped together based on similarity in their words, I note several characteristics that set clusters apart from each other. 
   One such aspect is time, as videos cluster together with other videos published at a similar point in time. 
   <!-- This is notable as time was not a variable fed into the UMAP algorithm that produced the clusterings.-->
   The chronological divide suggests that the content change, or evolve, throughout the timeline - in the time periods prior to the election to those after the inaugeration.
   <br><br>
   Another aspect is partisanship, as videos tend to group together with other videos sharing their political leaning. 
   This is not too surprising as the content of the videos largely depends on the format and vocabulary of the content creator, i.e. the political commentator, who in turn is used to code the partisan leaning.
   The partisan divide can in part be explained by the difference in source, potentially more so than the difference in how political positions are expressed.
   As such, this project could benefit from including more sources. Though it is always nicer to have more data.  

    </p>
  </div>
<br>
<br>
<br>
  
  
    <header class="w3-display-container w3-content w3-center" style="max-width:1500px">
      <!-- Navbar (placed at the bottom of the header image) -->
      <div class="w3-bar w3-light-grey w3-round w3-display-bottommiddle w3-hide-small" style="bottom:-16px">
        <a href="/" class="w3-bar-item w3-button">Return to Home Page</a>
      </div>
    </header>

    <!-- Navbar on small screens -->
    <header class="w3-center w3-light-grey w3-padding-16 w3-hide-large w3-hide-medium">
      <div class="w3-bar w3-light-grey">
        <a href="/" class="w3-bar-item w3-button">Return to Home Page</a>
        <!-- 
        <a href="#data" class="w3-bar-item w3-button">Data</a>
        <a href="#exploration" class="w3-bar-item w3-button">Exploration</a>
        -->
      </div>
    </header>
  <!-- Contact
  <div class="w3-light-grey w3-padding-large w3-padding-32 w3-margin-top" id="findings2">
    <h3 class="w3-center">Contact</h3>
    <hr>
    <p>Mauris neque quam, fermentum ut nisl vitae, convallis maximus nisl. Sed mattis nunc id lorem euismod placerat. Vivamus porttitor magna enim, ac accumsan tortor cursus at. Phasellus sed ultricies mi non congue ullam corper. Praesent tincidunt sed tellus.</p>

    <form action="/action_page.php" target="_blank">
      <div class="w3-section">
        <label>Name</label>
        <input class="w3-input w3-border" type="text" required name="Name">
      </div>
      <div class="w3-section">
        <label>Email</label>
        <input class="w3-input w3-border" type="text" required name="Email">
      </div>
      <div class="w3-section">
        <label>Message</label>
        <input class="w3-input w3-border" required name="Message">
      </div>
      <button type="submit" class="w3-button w3-block w3-dark-grey">Send</button>
    </form><br>
    <p>Powered by <a href="https://www.w3schools.com/w3css/default.asp" target="_blank" class="w3-hover-text-green">w3.css</a></p>

  </div>
	-->
<!-- Navbar (placed at the bottom of the header image) 
  <div class="w3-bar w3-light-grey w3-round w3-display-bottommiddle w3-hide-small" style="bottom:-16px">
    <a href="/" class="w3-bar-item w3-button">Home Page</a>
    <!-
    <a href="#data" class="w3-bar-item w3-button">Data</a>
    <a href="#exploration" class="w3-bar-item w3-button">Exploration</a> ->
  </div>
-->

  <!-- End page content -->
</div>
</div>

  

</body>
</html>
